{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[講義](https://nbviewer.jupyter.org/github/yenlung/nccu-jupyter-math/blob/master/1081%E8%A8%AD%E8%A8%88%E6%80%9D%E8%80%83%E8%88%87%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/D02.%20%E7%94%A8CNN%E5%9C%96%E5%BD%A2%E8%BE%A8%E8%AD%98%EF%BC%88%E9%82%84%E6%98%AFMNIST%EF%BC%89.ipynb)\n",
    "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。\n",
    "\n",
    "## 2-1 初始準備\n",
    "\n",
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 讀入 MNIST 數據庫\n",
    "### 由 Keras 讀入 MNIST\n",
    "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入格式整理\n",
    "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
    "\n",
    "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x135033860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train[1234]\n",
    "plt.imshow(x_train[1234], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 本身 Input 是矩陣\n",
    "# CNN 要的格式 28*28 的一張 (28, 28, 1)\n",
    "# 按照三張分色 或四張分色 就要有三張或四張()因為我們現在是灰階所以只要一張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出格式整理\n",
    "和上次一樣, 我們用標準 1-hot 方式處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為希望數字不要是 3.7 8.2 因為結果間沒有連續關係\n",
    "# one hot encoding\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]\n",
    "# 就會在第四個值是 1 其他都是 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 壓縮 0-1 (原是 0-255)\n",
    "# 數值大的容易成為關鍵\n",
    "# 不是 0-1 不能用統計的理論\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 打造你的 CNN\n",
    "決定神經網路架構、讀入相關套件\n",
    "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
    "\n",
    "我們上課的時候說過, 我們準備要做 3 次的 convolution + max-pooling, filter 大小都是 3×3。\n",
    "\n",
    "做 3 次 convolution, 每次都接 max-pooling\n",
    "filter 大小都是 3x3, max-pooling 都用 2x2 為一小區塊\n",
    "CNN 一個小技巧是每層的 filters 數目是越來越多, 上課同學建議第一層 4 個, 因為要做三次, 所以我們 filters 數分別是 4, 8, 16。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
    "\n",
    "只有 2 個隱藏層, 分別使用 17, 33 個神經元 (這也是同學建議)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 次 convolution 3 次 max-pooling\n",
    "# 2 層 dense\n",
    "\n",
    "# 輸出結果 0-9 有 10 個\n",
    "\n",
    "# maxpooling 2*2\n",
    "\n",
    "# convolution 1: filter(28*28)不算大， 4 個\n",
    "# convolution 2: 8 個\n",
    "# convolution 3: 16 個\n",
    "\n",
    "# filter 大小可以取大概 3*3 大家喜歡奇數\n",
    "\n",
    "# filter 應該要越來越多，因為基本原見的辨別應該沒有很多項、但是越高層開始從低層的結果組合，可以有更種搭配組合可能\n",
    "\n",
    "# 第一層 17 個神經元 \n",
    "# \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構我們的神經網路\n",
    "一開始一樣是打開個空白的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。padding 設成 same 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 個 filter 3*3的大小\n",
    "# 加邊緣記分板同樣大小\n",
    "# 第一層\n",
    "\n",
    "model.add(Conv2D(4, (3, 3), padding='same', input_shape=(28, 28, 1),\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二層\n",
    "model.add(Conv2D(8, (3, 3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不一定每次都要 maxpooling\n",
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三層\n",
    "model.add(Conv2D(16, (3, 3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling 最終回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected\n",
    "\n",
    "# 前面是 keras 自己做的 他知道有幾個神經員輸入\n",
    "model.add(Flatten())\n",
    "model.add(Dense(9, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(33, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果輸出\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝\n",
    "和之前比較不一樣的是我們還要做 compile 才正式把我們的神經網路建好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1305      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 33)                330       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                340       \n",
      "=================================================================\n",
      "Total params: 3,479\n",
      "Trainable params: 3,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 28*28 的圖 給 filter 3*3 用了 4 個 輸出的結果是 28*28 \n",
    "# 每一個 FILTER 只有一個 bias\n",
    "# 3*3*4 + 4 = 40\n",
    "# 跟圖片大小沒關係\n",
    "# 參數值不多\n",
    "\n",
    "# 296\n",
    "# 第一層後產生四張 28*28 的矩陣；所以有四層；要在乘上 4\n",
    "# 3*3*8*4 + 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0899 - accuracy: 0.1893\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0896 - accuracy: 0.2231\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0890 - accuracy: 0.2434\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0850 - accuracy: 0.2874\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0663 - accuracy: 0.5017\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0353 - accuracy: 0.7529\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0244 - accuracy: 0.8346\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0191 - accuracy: 0.8725\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0157 - accuracy: 0.8957\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0135 - accuracy: 0.9112\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0121 - accuracy: 0.9209\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 19s 324us/step - loss: 0.0108 - accuracy: 0.9295\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 19s 325us/step - loss: 0.0099 - accuracy: 0.9351\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0093 - accuracy: 0.9388\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0087 - accuracy: 0.9429\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0082 - accuracy: 0.9467\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0078 - accuracy: 0.9490\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0075 - accuracy: 0.9514\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0071 - accuracy: 0.9530\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0069 - accuracy: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14f4896a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=70, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5 結果測試\n",
    "### 分數\n",
    "我們來看測試資料 (我們的 CNN 沒看過的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 167us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看成績, 順便用 Python 3.6 開始的 f-string format 方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的 loss: 0.00589\n",
      "測試資料的正確率: 0.9606\n"
     ]
    }
   ],
   "source": [
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存結果\n",
    "結果看來還不差, 所以我們把結果存起來。上次我們介紹分別存架構和權重的方法, 這次我們看看怎麼樣一次就存入權重 + 結構!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欣賞一下成果\n",
    "我們示範一下怎麼讀回我們的神經網路。你會發現讀回來之後就可以直接使用了!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把我們原來的 model 刪掉, 保證接下來的是讀進來的。我們要用一個 load_model 的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.randint(1,9999, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test[pick[i]].reshape(28,28), cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
